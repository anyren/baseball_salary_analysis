{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85420be1",
   "metadata": {},
   "source": [
    "# EDA STARTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters_Adjusted_Salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# Best features according to correlation matrix\n",
    "\n",
    "df = df[[\"yearID\", \"playerID\", \"teamID\", \"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]\n",
    "\n",
    "# Best features from our group EDA discussion\n",
    "\n",
    "# df = df[[\"yearID\", \"playerID\", \"teamID\", \"G\", \"AB\", \"R\", \"H\", \"RBI\", \"ADJ Salary\"]]\n",
    "\n",
    "df[\"ADJ Salary\"] = df[\"ADJ Salary\"].astype(\"int\").round()\n",
    "\n",
    "df = df.loc[(df[\"ADJ Salary\"] > 0), :]\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"yearID\", \"playerID\"]).reset_index(drop=True)\n",
    "\n",
    "df.duplicated(subset=[\"yearID\", \"playerID\", \"teamID\"]).value_counts()\n",
    "\n",
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224141ad",
   "metadata": {},
   "source": [
    "# EDA - you can skip if you just want to jump to model creation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7159e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr = corr.style.background_gradient(cmap='Purples')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34df027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (15, 15))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.PairGrid(df[[\"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]).map_upper(plt.scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ffc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_hitter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b74f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yearID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"playerID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"teamID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0645b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"H\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"R\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RBI\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd662f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AB\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ceab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ADJ Salary\"].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86d9fb",
   "metadata": {},
   "source": [
    "# Binning salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d482eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon ADJ Salary\n",
    "bins = [0, 999999, 5999999, 10000000, 40000000]\n",
    "\n",
    "# Create labels for these bins\n",
    "group_labels = [\"< 1 mill\", \"1 mill to 5 mill\", \"6 mill to 10 mill\", \"> 10 mill\"]\n",
    "\n",
    "# Slice the data and place it into bins\n",
    "pd.cut(new_df[\"ADJ Salary\"], bins, labels=group_labels).head()\n",
    "\n",
    "new_df[\"ADJ Salary Group\"] = pd.cut(new_df[\"ADJ Salary\"], bins, labels=[1, 2, 3, 4])\n",
    "new_df.head()\n",
    "\n",
    "#Create a GroupBy object based upon ADJ Salary Group\n",
    "salary_group = new_df.groupby(\"ADJ Salary Group\")\n",
    "\n",
    "# Find how many rows fall into each bin\n",
    "print(salary_group[\"playerID\"].count())\n",
    "\n",
    "one_hots = pd.get_dummies(new_df[\"ADJ Salary Group\"], prefix=\"ADJ Salary Group\", prefix_sep=\"_\")\n",
    "one_hots\n",
    "\n",
    "ml_df = pd.concat([new_df, one_hots], axis=1)\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109de76c",
   "metadata": {},
   "source": [
    "# Vanilla LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55854022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml_df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906de549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c15c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71350c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6131cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"STD SCALER Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"STD SCALER Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\") \n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"NO SCALER Linear Regression Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"NO SCALER Linear Regression Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5c43e",
   "metadata": {},
   "source": [
    "# Improved LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79780d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml_df.copy()\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"] \n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"STD SCALER Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"STD SCALER Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\") \n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"NO SCALER Linear Regression Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"NO SCALER Linear Regression Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b593ffe1",
   "metadata": {},
   "source": [
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml_df.copy()\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"].values \n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb469eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "        \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fad329",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 5 provides the best accuracy where the classifier starts to stablize\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('k=5 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(cm_knn)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Note that each pair always adds up to exactly 1\n",
    "\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled[0:10])[:, 1]\n",
    "print(y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Random Forest offers\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"RandomForestClassifier Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RandomForestClassifier Testing Score: {clf.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "feature_importances = clf.feature_importances_ \n",
    "\n",
    "print(feature_importances)\n",
    "\n",
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,50)\n",
    "plt.margins(y=0.01)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbad5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(clf).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel RandomForestClassifier Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel RandomForestClassifier Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n\\nExtraTreesClassifier Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"ExtraTreesClassifier Testing Score: {model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "feature_importances = model.feature_importances_ \n",
    "\n",
    "features = sorted(zip(X.columns, model.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,50)\n",
    "plt.margins(y=0.01)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(model).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "model = ExtraTreesClassifier().fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Training Score: {model.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Testing Score: {model.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=10000) \n",
    "\n",
    "# Train the logistic regression model\n",
    "    \n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing scores\n",
    "\n",
    "print(f\"Training Data Score: {lr_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda585fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability for each class in the model\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print(y_pred_proba_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e628c46",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Show the confusion matrix for the logistic regression model\n",
    "    \n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(cm_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the logistic regression model\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86beef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
