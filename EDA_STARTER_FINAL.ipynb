{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85420be1",
   "metadata": {},
   "source": [
    "# EDA STARTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224141ad",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters_Adjusted_Salary.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41729280",
   "metadata": {},
   "source": [
    "## Can skip these if just running models =>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters_Adjusted_Salary.csv\")\n",
    "df.info()\n",
    "\n",
    "corr = df.corr()\n",
    "corr = corr.style.background_gradient(cmap='Purples')\n",
    "corr\n",
    "\n",
    "df.hist(figsize = (15, 15))  \n",
    "\n",
    "sns.PairGrid(df[[\"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]).map_upper(plt.scatter)\n",
    "\n",
    "df[\"yearID\"].value_counts()\n",
    "\n",
    "df[\"playerID\"].value_counts()\n",
    "\n",
    "df[\"teamID\"].value_counts()\n",
    "\n",
    "df[\"H\"].value_counts() \n",
    "\n",
    "df[\"R\"].value_counts() \n",
    "\n",
    "df[\"RBI\"].value_counts() \n",
    "\n",
    "df[\"AB\"].value_counts() \n",
    "\n",
    "df[\"ADJ Salary\"].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3e465",
   "metadata": {},
   "source": [
    "## Can skip these if just running models <="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "totalhits = df[\"H\"]\n",
    "doubles = df[\"2B\"]\n",
    "triples = df[\"3B\"]\n",
    "homeruns = df[\"HR\"]\n",
    "atbats = df[\"AB\"]\n",
    "walks = df[\"BB\"]\n",
    "hit_by_pitch = df[\"HBP\"]\n",
    "sac_hits = df[\"SH\"]\n",
    "sac_flies = df[\"SF\"]\n",
    "singles = (totalhits - homeruns - triples - doubles)\n",
    "\n",
    "df[\"slug_%\"] = (singles + 2*doubles + 3*triples + 4*homeruns) / atbats\n",
    "df[\"slug_%\"] = df[\"slug_%\"].fillna(0)\n",
    "df[\"avg\"] = totalhits / atbats\n",
    "df[\"avg\"] = df[\"avg\"].fillna(0)\n",
    "df[\"plate_appearances\"] = atbats + walks + hit_by_pitch + sac_hits + sac_flies\n",
    "df[\"avg\"] = df[\"avg\"].fillna(0)\n",
    "df[\"on_base_%\"] = (totalhits + walks + hit_by_pitch) / (atbats + walks + hit_by_pitch + sac_flies)\n",
    "df[\"on_base_%\"] = df[\"on_base_%\"].fillna(0)\n",
    "df[\"1B\"] = singles\n",
    "df[\"1B\"] = df[\"1B\"].fillna(0)\n",
    "\n",
    "df[\"ADJ Salary\"] = df[\"ADJ Salary\"].astype(\"int\").round()\n",
    "\n",
    "df = df.loc[(df[\"ADJ Salary\"] > 0), :]\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"yearID\", \"playerID\"], keep=False).reset_index(drop=True)\n",
    "\n",
    "df.duplicated(subset=[\"yearID\", \"playerID\", \"teamID\"]).value_counts()\n",
    "\n",
    "# Best features according to correlation matrix\n",
    "\n",
    "df = df[[\"yearID\", \"playerID\", \"teamID\", \"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]\n",
    "\n",
    "# Best features from our group EDA discussion\n",
    "\n",
    "# df = df[[\"yearID\", \"playerID\", \"teamID\", \"G\", \"AB\", \"R\", \"H\", \"RBI\", \"ADJ Salary\"]]\n",
    "\n",
    "# df = df[[\"yearID\", \"playerID\", \"teamID\", \"RBI\", \"avg\", \"on_base_%\", \"ADJ Salary\"]]\n",
    "\n",
    "# Weed out rookies\n",
    "\n",
    "no_rookies_df = df.groupby([\"playerID\"]).filter(lambda g: g[\"yearID\"].count() > 3)\n",
    "\n",
    "no_rookies_df = no_rookies_df.reset_index(drop=True)\n",
    "no_rookies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ff9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon ADJ Salary\n",
    "bins = [0, 999999, 5999999, 10000000, 40000000]\n",
    "\n",
    "# # Create labels for these bins\n",
    "# group_labels = [\"< 1 mill\", \"1 mill to 5 mill\", \"6 mill to 10 mill\", \"> 10 mill\"]\n",
    "\n",
    "# # Slice the data and place it into bins\n",
    "# pd.cut(new_df[\"ADJ Salary\"], bins, labels=np.arange(4)).head()\n",
    "\n",
    "no_rookies_df[\"ADJ Salary Group\"] = pd.cut(no_rookies_df[\"ADJ Salary\"], bins, labels=np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = no_rookies_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"cleaned_hitter_no_rookies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ab82c",
   "metadata": {},
   "source": [
    "# Linear Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"STD SCALER Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"STD SCALER Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\\n\\n\") \n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"NO SCALER Linear Regression Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"NO SCALER Linear Regression Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b80c89",
   "metadata": {},
   "source": [
    "# K-means benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e526468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Windows KMeans bug fix\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "\n",
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Finding the best value for k using the Elbow Curve\n",
    "inertia = []\n",
    "k = list(range(1, 9))\n",
    "\n",
    "# Calculate the inertia for the range of k values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow\n",
    "\n",
    "# Plot the elbow curve to find the best candidate(s) for k\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(list(range(11)))\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a20de",
   "metadata": {},
   "source": [
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "        \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 7 provides the best accuracy where the classifier starts to stablize\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"k=7 Test Acc: %.3f\" % knn.score(X_test_scaled, y_test))\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(cm_knn)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Note that each pair always adds up to exactly 1\n",
    "\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled[0:10])[:, 1]\n",
    "print(f\"Prediction probabilities: \\n\\n{y_pred_proba_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e4d1a",
   "metadata": {},
   "source": [
    "# Random Forest Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Random Forest offers\n",
    "\n",
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200, max_depth=7).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"RandomForestClassifier Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RandomForestClassifier Testing Score: {clf.score(X_test_scaled, y_test)}\\n\\n\")\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(clf).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200, max_depth=7).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel RandomForestClassifier Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel RandomForestClassifier Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff366f",
   "metadata": {},
   "source": [
    "# Extra Trees Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2866cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = ExtraTreesClassifier(max_depth=7).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"ExtraTreesClassifier Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"ExtraTreesClassifier Testing Score: {model.score(X_test_scaled, y_test)}\\n\\n\")\n",
    "\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(model).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "model = ExtraTreesClassifier(max_depth=7).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Training Score: {model.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Testing Score: {model.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada77fb4",
   "metadata": {},
   "source": [
    "# SVM Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model Accuracy\n",
    "\n",
    "print(f\"SVC Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVC Testing Score: {model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb78b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
