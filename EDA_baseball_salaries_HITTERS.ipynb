{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa14160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\" Reads dataset csv and returns pandas dataframe \"\"\"\n",
    "    \n",
    "    filepath = \"Hitters_Adjusted_Salary.csv\"\n",
    "\n",
    "    df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(a_df):\n",
    "    \"\"\" Returns deduped, na-dropped, index-reset dataframe \"\"\"    \n",
    "    \n",
    "    a_df = a_df.drop_duplicates()   \n",
    "        \n",
    "    a_df = a_df.dropna()\n",
    "    \n",
    "    a_df = a_df.drop([\"Unnamed: 0\", \"yearID\", \"playerID\", \"teamID\", \"lgID\", \"salary\", \"PO\", \"A\", \"E\", \"DP\"], axis=1)\n",
    "        \n",
    "    a_df = a_df.reset_index(drop=True)\n",
    "    \n",
    "    return a_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(a_df):\n",
    "    \"\"\" Returns dataframe with meaningful column names \"\"\"    \n",
    "    \n",
    "    abbr_dict = {\"GS\": \"games_started\", \"InnOuts\": \"inning_outs\", \"G\": \"games_played\", \"AB\": \"at_bats\",\\\n",
    "                \"R\": \"runs\", \"H\": \"hits\", \"2B\": \"doubles\", \"3B\": \"triples\", \"HR\": \"home_runs\",\\\n",
    "                \"RBI\": \"runs_batted_in\", \"SB\": \"stolen_bases\", \"CS\": \"caught_stealing\", \"BB\": \"base_on_balls\",\\\n",
    "                \"SO\": \"strike_outs\", \"IBB\": \"intentional_walks\", \"HBP\": \"hit_by_pitch\", \"SH\": \"sacrifice_hits\",\\\n",
    "                \"SF\": \"sacrifice_flies\", \"GIDP\": \"ground_into_double_play\"}\n",
    "    \n",
    "    a_df = a_df.rename(columns=abbr_dict)\n",
    "    \n",
    "    return a_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_dataset(a_df):\n",
    "    \"\"\" Provides summary info and visualizations of dataset \"\"\"\n",
    "    \n",
    "    print(a_df.info())\n",
    "           \n",
    "    print(f'\\n\\nADJ SALARY VALUE COUNTS: \\n {a_df[\"ADJ Salary\"].value_counts()}\\n\\n')\n",
    "    \n",
    "    a_df.hist(figsize = (15, 15))  \n",
    "    \n",
    "    sns.PairGrid(a_df[[\"hits\", \"runs_batted_in\", \"stolen_bases\", \"runs\", \"ground_into_double_play\"]]).map_upper(plt.scatter) # just scatter plot the float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(a_df):\n",
    "    \"\"\" Returns dataframe with target column removed, data scaled with standard scaler, data normalized, and labels \"\"\"\n",
    "    \n",
    "    salary_labels = a_df[\"ADJ Salary\"]    \n",
    "    no_target_df = a_df.drop(columns=[\"ADJ Salary\"])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(no_target_df)    \n",
    "    print(f\"SHAPE AFTER SCALING: {scaled_data.shape}\")\n",
    "\n",
    "    normalized_data = normalize(no_target_df)    \n",
    "    print(f\"SHAPE AFTER NORMALIZING: {normalized_data.shape}\")\n",
    "\n",
    "    return no_target_df, scaled_data, normalized_data, salary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_dataset(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rename_columns(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_dataset(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54567dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"ADJ Salary\"] = clean_df[\"ADJ Salary\"].astype(\"int\").round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4258b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"ADJ Salary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c81199",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = clean_df.drop([\"ADJ Salary\"], axis=1)\n",
    "y = clean_df[\"ADJ Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b581d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a43d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efdb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "\n",
    "print(f\"Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
