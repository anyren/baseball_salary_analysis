{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85420be1",
   "metadata": {},
   "source": [
    "# **LINEAR REGRESSION BLOCK START**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Hitters_Adjusted_Salary.csv\"\n",
    "df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "abbr_dict = {\"GS\": \"games_started\", \"InnOuts\": \"inning_outs\", \"G\": \"games_played\", \"AB\": \"at_bats\",\\\n",
    "                \"R\": \"runs\", \"H\": \"hits\", \"2B\": \"doubles\", \"3B\": \"triples\", \"HR\": \"home_runs\",\\\n",
    "                \"RBI\": \"runs_batted_in\", \"SB\": \"stolen_bases\", \"CS\": \"caught_stealing\", \"BB\": \"base_on_balls\",\\\n",
    "                \"SO\": \"strike_outs\", \"IBB\": \"intentional_walks\", \"HBP\": \"hit_by_pitch\", \"SH\": \"sacrifice_hits\",\\\n",
    "                \"SF\": \"sacrifice_flies\", \"GIDP\": \"ground_into_double_play\"}\n",
    "    \n",
    "df = df.rename(columns=abbr_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7537a",
   "metadata": {},
   "source": [
    "# Duplicate years code\n",
    "Everything in this block is figuring out the duplicate years issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = pd.DataFrame(df[['playerID', 'yearID']].groupby(['playerID', 'yearID']).value_counts().sort_values().reset_index(name='counts'))\n",
    "year_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_years_df = pd.merge(df, year_count, on=['playerID','yearID'])\n",
    "single_years_df = single_years_df.query('counts == 1')\n",
    "\n",
    "single_years_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf292ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = single_years_df.drop([\"Unnamed: 0\", \"yearID\", \"playerID\", \"teamID\", \"lgID\", \"salary\", \"PO\", \"A\", \"E\", \"DP\"], axis=1)\n",
    "cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "cleaned_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc07a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "(15023-12322)/15023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.query('playerID==\"whitema01\" & yearID==1996').sort_values('teamID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e41834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below requires downloading the original data from here: https://www.seanlahman.com/baseball-archive/statistics/\n",
    "filepath = \"core/Salaries.csv\"\n",
    "salary_df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"core/Batting.csv\"\n",
    "batting_df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "batting_df = batting_df[batting_df['yearID']>=1985]\n",
    "batting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(salary_df, batting_df, on=['playerID','yearID','teamID','lgID'])\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4f955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.query('playerID==\"whitema01\" & yearID==1996').sort_values('teamID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c57679",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = df[['playerID','yearID', 'salary', \"ADJ Salary\"]]\n",
    "red_comb_df = pd.merge(red_df, combined_df, on=['playerID','yearID','salary'],how=\"right\")\n",
    "red_comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29427f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_comb_df.query('playerID==\"whitema01\" & yearID==1996').sort_values('teamID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1836910",
   "metadata": {},
   "source": [
    "# END duplicate years code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa14160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\" Reads dataset csv and returns pandas dataframe \"\"\"\n",
    "    \n",
    "    filepath = \"Hitters_Adjusted_Salary.csv\"\n",
    "\n",
    "    df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a9f3f",
   "metadata": {},
   "source": [
    "## Keep this Code!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(a_df):\n",
    "    \"\"\" Returns deduped, na-dropped, index-reset dataframe \"\"\"    \n",
    "    year_count = pd.DataFrame(a_df[['playerID', 'yearID']].groupby(['playerID', 'yearID']).value_counts().sort_values().reset_index(name='counts'))\n",
    "    single_years_df = pd.merge(df, year_count, on=['playerID','yearID'])\n",
    "    a_df = single_years_df.query('counts == 1')\n",
    "    \n",
    "    a_df = a_df.drop_duplicates()   \n",
    "        \n",
    "    a_df = a_df.dropna()\n",
    "    \n",
    "    a_df = a_df.drop([\"Unnamed: 0\", \"yearID\", \"playerID\", \"teamID\", \"lgID\", \"salary\", \"PO\", \"A\", \"E\", \"DP\",'counts'], axis=1)\n",
    "        \n",
    "    a_df = a_df.reset_index(drop=True)\n",
    "    \n",
    "    return a_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(a_df):\n",
    "    \"\"\" Returns dataframe with meaningful column names \"\"\"    \n",
    "    \n",
    "    abbr_dict = {\"GS\": \"games_started\", \"InnOuts\": \"inning_outs\", \"G\": \"games_played\", \"AB\": \"at_bats\",\\\n",
    "                \"R\": \"runs\", \"H\": \"hits\", \"2B\": \"doubles\", \"3B\": \"triples\", \"HR\": \"home_runs\",\\\n",
    "                \"RBI\": \"runs_batted_in\", \"SB\": \"stolen_bases\", \"CS\": \"caught_stealing\", \"BB\": \"base_on_balls\",\\\n",
    "                \"SO\": \"strike_outs\", \"IBB\": \"intentional_walks\", \"HBP\": \"hit_by_pitch\", \"SH\": \"sacrifice_hits\",\\\n",
    "                \"SF\": \"sacrifice_flies\", \"GIDP\": \"ground_into_double_play\"}\n",
    "    \n",
    "    a_df = a_df.rename(columns=abbr_dict)\n",
    "    \n",
    "    return a_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_dataset(a_df):\n",
    "    \"\"\" Provides summary info and visualizations of dataset \"\"\"\n",
    "    \n",
    "    print(a_df.info())\n",
    "    \n",
    "    a_df.hist(figsize = (15, 15))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24be60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_salaries(a_df):\n",
    "    \"\"\" Returns dataframe with salary column made into int and rounded \"\"\"\n",
    "\n",
    "    a_df[\"ADJ Salary\"] = a_df[\"ADJ Salary\"].astype(\"int\").round()\n",
    "\n",
    "    return a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db811e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(a_df):\n",
    "    \"\"\" Runs linear regression on dataframe, prints model scores \"\"\"\n",
    "\n",
    "    # Assign X and y\n",
    "\n",
    "    X = a_df.drop([\"log_of_salary\", \"ADJ Salary\"], axis=1)\n",
    "    y = a_df[\"log_of_salary\"]\n",
    "    print(X.columns)\n",
    "    \n",
    "    # Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Create a scaler to standardize the data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Train the scaler with the X_train data.\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform X_train and X_test.\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "    \n",
    "    predicted = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    \n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\") \n",
    "    \n",
    "    # Score the model\n",
    "\n",
    "    print(f\"Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\")  \n",
    "    \n",
    "    plt.bar(np.arange(len(model.coef_)), model.coef_)\n",
    "    plt.title(f'Linear Regression coefficient plot')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LASSO(a_df):\n",
    "    \"\"\" Runs LASSO regression on dataframe, prints model scores \"\"\"\n",
    "\n",
    "    # Assign X and y\n",
    "\n",
    "    X = a_df.drop([\"log_of_salary\", \"ADJ Salary\"], axis=1)\n",
    "    y = a_df[\"log_of_salary\"]\n",
    "    \n",
    "    # Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Create a scaler to standardize the data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Train the scaler with the X_train data.\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform X_train and X_test.\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    lasso_reg = Lasso().fit(X_train, y_train)\n",
    "\n",
    "    predicted = lasso_reg.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    \n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\") \n",
    "\n",
    "    # Score the model\n",
    "\n",
    "    print(f\"LASSO Regression Training Data Score: {lasso_reg.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"LASSO Regression Testing Data Score: {lasso_reg.score(X_test_scaled, y_test)}\")\n",
    "    \n",
    "    plt.bar(np.arange(len(lasso_reg.coef_)), lasso_reg.coef_)\n",
    "    plt.title(f'LASSO Regression coefficient plot')\n",
    "    plt.show()  \n",
    "    \n",
    "    sel = SelectFromModel(lasso_reg)\n",
    "    sel.fit(X_train_scaled, y_train)\n",
    "    SelectFromModel(estimator=Lasso())\n",
    "    \n",
    "    X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_selected_train)\n",
    "    \n",
    "    X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "    X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "    new_lasso_reg = LinearRegression().fit(X_selected_train_scaled, y_train)\n",
    "    print(f\"New linear regression score: {new_lasso_reg.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6859b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Ridge(a_df):\n",
    "    \"\"\" Runs Ridge regression on dataframe, prints model scores \"\"\"\n",
    "\n",
    "    # Assign X and y\n",
    "\n",
    "    X = a_df.drop([\"log_of_salary\",'ADJ Salary'], axis=1)\n",
    "    y = a_df[\"log_of_salary\"]\n",
    "    print(X.columns)\n",
    "    # Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Create a scaler to standardize the data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Train the scaler with the X_train data.\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform X_train and X_test.\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    ridge_reg = Ridge().fit(X_train, y_train)\n",
    "\n",
    "    predicted = ridge_reg.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    \n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\") \n",
    "\n",
    "    # Score the model\n",
    "\n",
    "    print(f\"Ridge Regression Training Data Score: {ridge_reg.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"Ridge Regression Testing Data Score: {ridge_reg.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "    plt.bar(np.arange(len(ridge_reg.coef_)), ridge_reg.coef_)\n",
    "    plt.title(f'Ridge Regression coefficient plot')\n",
    "    plt.show()     \n",
    "    \n",
    "    sel = SelectFromModel(ridge_reg)\n",
    "    sel.fit(X_train_scaled, y_train)\n",
    "    SelectFromModel(estimator=Ridge())\n",
    "    print(sel.get_support())\n",
    "    \n",
    "    X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "  \n",
    "    scaler = StandardScaler().fit(X_selected_train)\n",
    "    \n",
    "    X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "    X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "    new_ridge_reg = LinearRegression().fit(X_selected_train_scaled, y_train)\n",
    "    print(f\"New linear regression score: {new_ridge_reg.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ElasticNet(a_df):\n",
    "    \"\"\" Runs ElasticNet regression on dataframe, prints model scores \"\"\"\n",
    "\n",
    "    # Assign X and y\n",
    "\n",
    "    X = a_df.drop([\"log_of_salary\", \"ADJ Salary\"], axis=1)\n",
    "    y = a_df[\"log_of_salary\"]\n",
    "    \n",
    "    # Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Create a scaler to standardize the data\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Train the scaler with the X_train data.\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform X_train and X_test.\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    elasticnet_reg = ElasticNet().fit(X_train, y_train)\n",
    "      \n",
    "    predicted = elasticnet_reg.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    \n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\") \n",
    "\n",
    "    # Score the model\n",
    "\n",
    "    print(f\"ElasticNet Regression Training Data Score: {elasticnet_reg.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"ElasticNet Regression Testing Data Score: {elasticnet_reg.score(X_test_scaled, y_test)}\")\n",
    "    \n",
    "    plt.bar(np.arange(len(elasticnet_reg.coef_)), elasticnet_reg.coef_)\n",
    "    plt.title(f'ElasticNet Regression coefficient plot')\n",
    "    plt.show()  \n",
    "    \n",
    "    sel = SelectFromModel(elasticnet_reg)\n",
    "    sel.fit(X_train_scaled, y_train)\n",
    "    SelectFromModel(estimator=ElasticNet())\n",
    "    \n",
    "    X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_selected_train)\n",
    "    \n",
    "    X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "    X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "    new_elasticnet_reg = LinearRegression().fit(X_selected_train_scaled, y_train)\n",
    "    print(f\"New linear regression score: {new_elasticnet_reg.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df[\"ADJ Salary\"] = loaded_df[\"ADJ Salary\"].astype(int)\n",
    "\n",
    "loaded_df = loaded_df.loc[~(loaded_df[\"ADJ Salary\"] <= 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_dataset(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rename_columns(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_dataset(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = round_salaries(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"log_of_salary\"] = np.log(clean_df[\"ADJ Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"log_of_salary\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_regression(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_regression(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bef03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_LASSO(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_Ridge(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33212ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337400e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ElasticNet(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc4c28",
   "metadata": {},
   "source": [
    "# Results:\n",
    "\n",
    "- Using the logarithm of the ADJ Salary column values improved the regression score\n",
    "    - I had to eliminate any salary values <= 0 to make this work\n",
    "- Ridge regression achieved the best score: 0.7291495360671353"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f748a1",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "\n",
    "- Add / remove features from the dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879019f",
   "metadata": {},
   "source": [
    "# **LINEAR REGRESSION BLOCK END**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161922f",
   "metadata": {},
   "source": [
    "# **PCA START BLOCK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b69219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c358d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ADJ Salary column\n",
    "clean_df2= clean_df.drop([\"ADJ Salary\"], axis=1)\n",
    "clean_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5aba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset so that columns that contain larger values do not influence the outcome more than columns with smaller values.\n",
    "clean_scaled = StandardScaler().fit_transform(clean_df2)\n",
    "print(clean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction with PCA preserving 90% of the explained variance ( n_components=0.90)\n",
    "# Initialize PCA model\n",
    "pca = PCA(n_components=0.90)\n",
    "\n",
    "# Get two principal components for the iris data.\n",
    "clean_pca = pca.fit_transform(clean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f18e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_pca = pd.DataFrame(data=clean_pca)\n",
    "clean_df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a872dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform PCA data to a DataFrame\n",
    "clean_df_pca = pd.DataFrame(data=clean_pca, columns=[\"principal component 1\", \"principal component 2\",\n",
    "                                                                \"principal component 3\",\"principal component 4\",\n",
    "                                                                 \"principal component 5\",\"principal component 6\",\n",
    "                                                                 \"principal component 7\",\"principal component 8\"])\n",
    "clean_df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_pca.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e439351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further reduce the dataset dimensions with t-SNE\n",
    "\n",
    "# Initialize t-SNE model\n",
    "tsne = TSNE(learning_rate = 50)\n",
    "\n",
    "# Reduce dimensions\n",
    "tsne_features = tsne.fit_transform(clean_pca)\n",
    "\n",
    "# The dataset has 2 columns\n",
    "tsne_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343737fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to plot the dataset\n",
    "\n",
    "# The first column of transformed features\n",
    "clean_df2[\"x\"] = tsne_features[:,0]\n",
    "\n",
    "# The second column of transformed features\n",
    "clean_df2[\"y\"] = tsne_features[:,1]\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(clean_df2[\"x\"],clean_df2[\"y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ad728",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clean_df[\"ADJ Salary\"]\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36305032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters with color\n",
    "plt.scatter(clean_df2[\"x\"],clean_df2[\"y\"], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c68a3",
   "metadata": {},
   "source": [
    "# Perform a Cluster Analysis with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38510602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Windows KMeans bug fix. \n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best value for k using the Elbow Curve\n",
    "inertia = []\n",
    "k = list(range(1, 9))\n",
    "\n",
    "# Calculate the inertia for the range of k values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(clean_df_pca)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76499fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow curve to find the best candidate(s) for k\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(list(range(11)))\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920af8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If possible, determine where the elbow of the plot is, and at which value of k it appears.\n",
    "# Create a function called `get_clusters(k, data)` that finds the `k` clusters using K-Means on `data`. The function should return a DataFrame copy of `Data` that should include a new column containing the clusters found.\n",
    "\n",
    "def get_clusters(k, data):\n",
    "    # Initialize the K-Means model\n",
    "    model = KMeans(n_clusters=k, random_state=0)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(data)\n",
    "\n",
    "    # Predict clusters\n",
    "    predictions = model.predict(data)\n",
    "\n",
    "    # Create return DataFrame with predicted clusters\n",
    "    data[\"class\"] = model.labels_\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e50a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_clusters(4, clean_df_pca)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clusters(df):\n",
    "    plt.scatter(df['principal component 1'], df['principal component 2'], c=df['class'])\n",
    "    plt.xlabel('principal component 1')\n",
    "    plt.ylabel('principal component 2')\n",
    "    plt.title(\"ADJ Salary clusters\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8b65a",
   "metadata": {},
   "source": [
    "# **PCA END BLOCK**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
