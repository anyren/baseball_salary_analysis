{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85420be1",
   "metadata": {},
   "source": [
    "## After our first attempts at multivariate linear regression disappointed, we switched our strategy at TA Colin's suggestion: why not bin the ADJ Salary target variable and make this a classification problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have a version of the dataset saved for reuse\n",
    "\n",
    "df = pd.read_csv(\"../Resources/salary_integers_df.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remembering the \"features of interest\" from our previous exploratory data analysis\n",
    "\n",
    "df = df[[\"GS\", \"BB\", \"RBI\", \"R\", \"HR\", \"InnOuts\", \"ADJ Salary\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ff9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon ADJ Salary\n",
    "\n",
    "# 0 = <= $1m\n",
    "# 1 = $1-6m\n",
    "# 2 = $6-10m\n",
    "# 3 = >$10m\n",
    "\n",
    "bins = [0, 999999, 5999999, 10000000, 40000000]\n",
    "\n",
    "df[\"ADJ Salary Group\"] = pd.cut(df[\"ADJ Salary\"], bins, labels=np.arange(4))\n",
    "\n",
    "df[\"ADJ Salary Group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Resources/binned_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b80c89",
   "metadata": {},
   "source": [
    "# K-means benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e526468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Windows KMeans bug fix\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\"])\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Finding the best value for k using the Elbow Curve\n",
    "inertia = []\n",
    "k = list(range(1, 9))\n",
    "\n",
    "# Calculate the inertia for the range of k values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow\n",
    "\n",
    "# Plot the elbow curve to find the best candidate(s) for k\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(list(range(11)))\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a20de",
   "metadata": {},
   "source": [
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\"])\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "        \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 9 provides the best accuracy where the classifier starts to stablize\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"k=9 Test Acc: %.3f\" % knn.score(X_test_scaled, y_test))\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(cm_knn)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Note that each pair always adds up to exactly 1\n",
    "\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled[0:10])[:, 1]\n",
    "print(f\"Prediction probabilities: \\n\\n{y_pred_proba_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e4d1a",
   "metadata": {},
   "source": [
    "# Random Forest Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Random Forest offers\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\"])\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200, max_depth=7).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"RandomForestClassifier Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RandomForestClassifier Testing Score: {clf.score(X_test_scaled, y_test)}\\n\\n\")\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(clf).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200, max_depth=7).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel RandomForestClassifier Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel RandomForestClassifier Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff366f",
   "metadata": {},
   "source": [
    "# Extra Trees Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2866cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\"])\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = ExtraTreesClassifier(max_depth=7).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"ExtraTreesClassifier Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"ExtraTreesClassifier Testing Score: {model.score(X_test_scaled, y_test)}\\n\\n\")\n",
    "\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(model).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "model = ExtraTreesClassifier(max_depth=7).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Training Score: {model.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Testing Score: {model.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada77fb4",
   "metadata": {},
   "source": [
    "# SVM Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\"])\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model Accuracy\n",
    "\n",
    "print(f\"SVC Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"SVC Testing Score: {model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275dcd5f",
   "metadata": {},
   "source": [
    "## These results are disappointing.  Our best testing accuracy is approximately 56%. We'll pursue another course of action ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
