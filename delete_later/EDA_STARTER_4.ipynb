{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85420be1",
   "metadata": {},
   "source": [
    "# EDA STARTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters_Adjusted_Salary.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# Best features according to correlation matrix\n",
    "\n",
    "df = df[[\"yearID\", \"playerID\", \"teamID\", \"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]\n",
    "\n",
    "# Best features from our group EDA discussion\n",
    "\n",
    "# df = df[[\"yearID\", \"playerID\", \"teamID\", \"G\", \"AB\", \"R\", \"H\", \"RBI\", \"ADJ Salary\"]]\n",
    "\n",
    "df[\"ADJ Salary\"] = df[\"ADJ Salary\"].astype(\"int\").round()\n",
    "\n",
    "df = df.loc[(df[\"ADJ Salary\"] > 0), :]\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"yearID\", \"playerID\"]).reset_index(drop=True)\n",
    "\n",
    "df.duplicated(subset=[\"yearID\", \"playerID\", \"teamID\"]).value_counts()\n",
    "\n",
    "no_rookies_df = df.groupby([\"playerID\"]).filter(lambda g: g[\"yearID\"].count() > 3)\n",
    "no_rookies_df = no_rookies_df.reset_index(drop=True)\n",
    "no_rookies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ff9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon ADJ Salary\n",
    "bins = [0, 999999, 5999999, 10000000, 40000000]\n",
    "\n",
    "# # Create labels for these bins\n",
    "# group_labels = [\"< 1 mill\", \"1 mill to 5 mill\", \"6 mill to 10 mill\", \"> 10 mill\"]\n",
    "\n",
    "# # Slice the data and place it into bins\n",
    "# pd.cut(new_df[\"ADJ Salary\"], bins, labels=np.arange(4)).head()\n",
    "\n",
    "no_rookies_df[\"ADJ Salary Group\"] = pd.cut(no_rookies_df[\"ADJ Salary\"], bins, labels=np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = no_rookies_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ab82c",
   "metadata": {},
   "source": [
    "# Linear Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "df\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"]\n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"STD SCALER Linear Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"STD SCALER Linear Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\\n\\n\") \n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "\n",
    "print(f\"NO SCALER Linear Regression Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"NO SCALER Linear Regression Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b80c89",
   "metadata": {},
   "source": [
    "# K-means benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e526468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "\n",
    "#Windows KMeans bug fix\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"].values\n",
    "\n",
    "# Finding the best value for k using the Elbow Curve\n",
    "inertia = []\n",
    "k = list(range(1, 9))\n",
    "\n",
    "# Calculate the inertia for the range of k values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow\n",
    "\n",
    "# Plot the elbow curve to find the best candidate(s) for k\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(list(range(11)))\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a20de",
   "metadata": {},
   "source": [
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()\n",
    "\n",
    "# Assign X and y\n",
    "\n",
    "X = df.drop(columns=[\"ADJ Salary\", \"ADJ Salary Group\", \"yearID\", \"playerID\", \"teamID\"], axis=1)\n",
    "y = df[\"ADJ Salary Group\"].values \n",
    "\n",
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "\n",
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "        \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()\n",
    "\n",
    "X.columns\n",
    "\n",
    "# Note that k: 9 provides the best accuracy where the classifier starts to stablize\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(cm_knn)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Note that each pair always adds up to exactly 1\n",
    "\n",
    "y_pred_proba_knn = knn.predict_proba(X_test_scaled[0:10])[:, 1]\n",
    "print(y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e4d1a",
   "metadata": {},
   "source": [
    "# Random Forest Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Random Forest offers\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"RandomForestClassifier Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"RandomForestClassifier Testing Score: {clf.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "feature_importances = clf.feature_importances_ \n",
    "\n",
    "print(feature_importances)\n",
    "\n",
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,50)\n",
    "plt.margins(y=0.01)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(clf).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=200).fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel RandomForestClassifier Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel RandomForestClassifier Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff366f",
   "metadata": {},
   "source": [
    "# Extra Trees Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2866cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n\\nExtraTreesClassifier Training Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"ExtraTreesClassifier Testing Score: {model.score(X_test_scaled, y_test)}\")\n",
    "\n",
    "feature_importances = model.feature_importances_ \n",
    "\n",
    "features = sorted(zip(X.columns, model.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,50)\n",
    "plt.margins(y=0.01)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Now try with the selected features\n",
    "\n",
    "sel = SelectFromModel(model).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=0)\n",
    "\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "model = ExtraTreesClassifier().fit(X_selected_train_scaled, y_train)\n",
    "\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Training Score: {model.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"SelectFromModel ExtraTreesClassifier Testing Score: {model.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b3be7",
   "metadata": {},
   "source": [
    "# PCA/T-SNE Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761dab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset so that columns that contain larger values do not influence the outcome more than columns with smaller values.\n",
    "clean_scaled = StandardScaler().fit_transform(X)\n",
    "print(clean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction with PCA preserving 90% of the explained variance ( n_components=0.90)\n",
    "# Initialize PCA model\n",
    "pca = PCA(n_components=0.90)\n",
    "\n",
    "# Get two principal components for the iris data.\n",
    "clean_pca = pca.fit_transform(clean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_pca = pd.DataFrame(data=clean_pca)\n",
    "clean_df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further reduce the dataset dimensions with t-SNE\n",
    "\n",
    "# Initialize t-SNE model\n",
    "tsne = TSNE(learning_rate = 50)\n",
    "\n",
    "# Reduce dimensions\n",
    "tsne_features = tsne.fit_transform(clean_pca)\n",
    "\n",
    "# The dataset has 2 columns\n",
    "tsne_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to plot the dataset\n",
    "\n",
    "# The first column of transformed features\n",
    "clean_df_pca[\"x\"] = tsne_features[:,0]\n",
    "\n",
    "# The second column of transformed features\n",
    "clean_df_pca[\"y\"] = tsne_features[:,1]\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(clean_df_pca[\"x\"],clean_df_pca[\"y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_df[\"ADJ Salary\"]\n",
    "labels.value_counts()\n",
    "\n",
    "# Visualize the clusters with color\n",
    "plt.scatter(clean_df_pca[\"x\"],clean_df_pca[\"y\"], c=labels)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224141ad",
   "metadata": {},
   "source": [
    "# EDA - you can skip if you just want to jump to model creation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7159e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr = corr.style.background_gradient(cmap='Purples')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34df027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (15, 15))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.PairGrid(df[[\"GS\", \"AB\", \"R\", \"H\", \"2B\", \"GIDP\", \"IBB\", \"BB\", \"RBI\", \"HR\", \"ADJ Salary\"]]).map_upper(plt.scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ffc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_hitter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b74f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yearID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"playerID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"teamID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0645b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"H\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"R\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RBI\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd662f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AB\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ceab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ADJ Salary\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"G\").add_legend()\n",
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"AB\").add_legend()\n",
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"R\").add_legend()\n",
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"H\").add_legend()\n",
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"RBI\").add_legend()\n",
    "sns.FacetGrid(ml_df, hue=\"ADJ Salary Group\", size=5).map(sns.distplot,\"ADJ Salary\").add_legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# df = df[[\"yearID\", \"playerID\", \"teamID\", \"G\", \"AB\", \"R\", \"H\", \"RBI\", \"ADJ Salary\"]]\n",
    "\n",
    "sns.boxplot(x=\"ADJ Salary Group\", y=\"G\", data=ml_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"ADJ Salary Group\", y=\"AB\", data=ml_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"ADJ Salary Group\", y=\"R\", data=ml_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"ADJ Salary Group\", y=\"H\", data=ml_df)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=\"ADJ Salary Group\", y=\"RBI\", data=ml_df)\n",
    "plt.show()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.pairplot(ml_df[[\"G\", \"AB\", \"R\", \"H\", \"RBI\", \"ADJ Salary Group\"]], hue=\"ADJ Salary Group\", size=3);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
